
---
title: "Comparison_SCNA"
author: "Chiara Schiller"
date: "2023-04-17"
output: html_document
---

## Compare all tools, results saved in folder 2 up

```{r}

# Install packages
library(FactoMineR)
library(ggcorrplot)
library(corrr)
library(readr)
library(ggfortify)
library(ggplot2)
library(randomForestSRC)
library(caret)
library(tidyverse)

```

Load in all different result files
```{r}
csv_dir = "./../../results_Risom/"
data <- list.files(path = csv_dir, recursive = FALSE, pattern = "\\_sublineage.csv$")
all = list()
for (i in 1:length(data)){
  all[[i]] <- as.data.frame(read_csv(paste0(csv_dir,data[i])))
  #rownames(all[[i]]) = sub("4ct_self", "", as.vector(all[[i]][,1]))
  rownames(all[[i]]) = as.vector(all[[i]][,1])
  rownames(all[[i]]) = sub(".csv", "", rownames(all[[i]]))
  all[[i]] = all[[i]][,-1]


# switch interactions colnames Misty
colnames(all[[i]]) = sub("(.*)_(.*)", "\\2_\\1", colnames(all[[i]]))}

#switch back for histoCAT
for(i in grep("histo", data)){
  colnames(all[[i]]) = sub("(.*)_(.*)", "\\2_\\1", colnames(all[[i]]))
}
data
```
Make correct order of features and double the features for Giotto as asymmetric

```{r}

# select giotto dataframe
giotto_inidces <- which(sapply(all, function(df) ncol(df) ==153))

for (i in giotto_inidces){
  dob <- all[[i]][, !sapply(colnames(all[[i]]), function(col) {
  parts <- strsplit(col, "_")[[1]]
  length(parts) == 2 && parts[1] == parts[2]
})]
  colnames(dob) = sub("(.*)_(.*)", "\\2_\\1", colnames(dob))
  all[[i]] = cbind(all[[i]] , dob)
}

# correct order for ground truth later 
ordered_cols <- colnames(all[[2]])
# Combine the results into the stat list, exclude basline dataset from ordering
for (i in 1:length(all)) { 
  if(ncol(all[[i]]) > 50)
      # Reorder rows of dataset1 using the ordered row names
      all[[i]] <- all[[i]][, ordered_cols , drop = FALSE]
}
sum(colnames(all[[2]]) %in% colnames(all[[4]]))
```



Gereate datasets with only the two groups to compare, give it the right naming and then the rest of the script should stay the same :)
```{r}
all[[3]]
```
HEEEERRRRREEEEE how to compare!!!!!!!!!
 Naming convention: Tool_x_vs_y

 

Create heatmap for all to see, what to expect
```{r}
library(tidyverse)
library(factoextra)
library(pheatmap)

names(all) = data
meta = read_csv("./../../../../../data/Risom_breast/Table_S1_Patient_Feature_Table.csv")
table(meta$Status)
status = meta$Status
status = status[grepl("progressor", status)]
status = data.frame(row.names = rownames(all[[1]]), status = factor(status))


for (i in 1:length(all)){
  pheatmap(all[[i]], treeheight_row = 0, treeheight_col = 0, main = names(all)[i], cluster_rows = F)
}

```
Create PCA plot of all results
```{r}
meta = read_csv("./../../../../../data/Risom_breast/Table_S1_Patient_Feature_Table.csv")
status = meta$Status


for (i in 1:length(all)){
df = all[[i]]
df = df[grep("progressor", status), ]
status = status[grepl("progressor", status)]
# some datasets have zero variance column (sigval in histocat). They cannot be scaled
  if(0 %in% apply(df, 2, sd)){
    pca_res <- prcomp(df)
  }else{
    pca_res <- prcomp(df, scale. = TRUE)
  }
df$group = status

print(autoplot(pca_res, data = df, colour = 'group') +
      ggtitle(names(all)[i]) +
        theme_bw()
      )
}

# save one plot to show purpose


#df = all[[143]]
#pca_res <- prcomp(df, scale. = TRUE)
#df$group = sub("_ab.*", "", rownames(df))###

#png("./../../../../Figures/raw/Comparison/PCA_SEA_example.png", height = 400, width = 600, res = 150)
#autoplot(pca_res, data = df, colour = 'group') +
#      ggtitle(names(all)[143]) +
#        theme_bw()
#dev.off()

```
Create comparison of interactino score distributions
```{r}
# select column of interest (specific cell cell interaction)
COI = 2


for (i in 1:length(all)){
  groups = rep(unlist(strsplit(names(all[i]), "_vs_")), each = 100)
  data = as.data.frame(cbind(rownames(all[[i]]), as.numeric(all[[i]][,COI]), groups))
  data$V2 = as.numeric(data$V2)
  
  print(ggplot(data, aes(x = V2)) +
  geom_histogram() +
  facet_grid(. ~ groups) +
  labs(title = names(all)[i], x = "interaction_value", y = "Frequency") +
    theme_classic()
  )
  
}

```
Create defining group columns within datasets

Now it has two columns more, point number and status of progressor/non-progressor
```{r}
df_list = list()

for (i in 1:length(all)){
  #all[[i]]$preference <- sub("_ab.*sim_\\d+$", "", rownames(all[[i]]))
  #all[[i]]$preference <- sub("self_", "self0_", all[[i]]$preference)
  all[[i]] = all[[i]][grep("progressor", status), ]

}

```

Set functions for random forest and F1 statistics
```{r}
stat = list()
# Load required packages
library(caret)
library(randomForest)
# Create an index variable for the two groups
group_index <- status

# write F1 and FDR function
# Calculate the F1 score
F1_Score <- function(predictions, actual) {
  TP <- sum(predictions == "nonprogressor" & actual == "nonprogressor")
  FP <- sum(predictions == "nonprogressor" & actual == "progressor")
  FN <- sum(predictions == "progressor" & actual == "nonprogressor")
  precision <- TP / (TP + FP)
  recall <- TP / (TP + FN)
  F1 <- 2 * precision * recall / (precision + recall)
  FDR <- FP / (TP + FP)
  return(c(F1, FDR))
}

# Set seed for reproducibility
set.seed(123)
```

Fix connection issue
```{r}
unregister_dopar <- function() {
  env <- foreach:::.foreachGlobals
  rm(list=ls(name=env), pos=env)
}
unregister_dopar()
```


Parallelize 100 iterations
```{r}
library(foreach)
library(doParallel)
library(caret)
library(randomForest)


# Set the number of cores to use
num_cores <- 6
cl <- makeCluster(num_cores)
registerDoParallel(cl)
importances = list()
# Set the number of iterations
num_iterations <- 100

# Create a list to store the results
stat <- list()

# Loop over the data
foreach(i = 1:length(all), .combine = c, .packages = c("caret","randomForest", "tidyverse")) %dopar% {
  # Combine index variable with data
  data <- cbind(all[[i]], group_index)
  
  
  # Create a list to store the results for this iteration
  result <- list()
  
  for (x in 1:num_iterations){
    #downsamle majority class for balanced dataset
    prog = rownames(data[data$group_index == "progressor",])
    nonprog = sample(rownames(data[data$group_index == "nonprogressor",]), min(table(status)),replace = FALSE)
    
    data = data[rownames(data) %in% c(prog, nonprog), ]
    # Split data into training and test sets
    
    trainIndex <- caret::createDataPartition(data$group_index, p = 0.8, list = FALSE, times = 1)
    train <- data[trainIndex, ]
    test <- data[-trainIndex, ]

    # Define the model
    model <- caret::train(group_index ~ ., data = train, method = "rf", trControl = trainControl(method = "cv", number = 5))
    
    # Make predictions on the test set
    predictions <- predict(model, newdata = test)

    # Store the result for this iteration
    importances[[x]] <- varImp(model$finalModel)
    result[[x]] <- F1_Score(predictions, test$group_index)
  }
  # Combine the results for this iteration into the stat list
  names(importances) <- paste(i, seq_along(importances), sep = "_")
  names(result) <- paste(i, seq_along(result), sep = "_")
  list(result, importances)
} -> result_list

# Stop the parallel backend
stopCluster(cl)
registerDoSEQ()
stat = list()
F1 = result_list[seq(1, length(result_list), by = 2)]
# Combine the results into the stat list
for (i in seq_along(F1)) {
  
  stat[[i]] <- do.call("rbind", F1[[i]])
}

#saveRDS(result_list, "./../../results_4ct_sym/rf_result_lists/sym_complete.rds")
#see = readRDS("./../../results_4ct_cross01/count_histoCATSEA_result_list_4ct_cross01.rds")

#result_list = readRDS("./../../results_4ct_asym_0.2grid_self/Misty_cross/Misty_F1_correct_order.rds")
# loading results wo spatialLDA
#all = all[c(1:length(all)) %notin% grep("SpatialLDA", names(all))]
```

Make an F1 baseline with scrambled labels to show interpretability of results

```{r}
library(foreach)
library(doParallel)
library(caret)
library(randomForest)

# Set the number of cores to use
num_cores <- 6
cl <- makeCluster(num_cores)
registerDoParallel(cl)
importances = list()
# Set the number of iterations
num_iterations <- 100
scramble <- rep(rep(c("A","B"), each=1), 100)
# Create a list to store the results
stat <- list()

# Loop over the data
foreach(i = 1, .combine = c, .packages = c("caret","randomForest")) %dopar% {
  # Combine index variable with data
  data <- cbind(all[[i]], scramble)
  # Create a list to store the results for this iteration
  result <- list()
  
  for (x in 1:num_iterations){
    # Split data into training and test sets
    trainIndex <- caret::createDataPartition(data$scramble, p = 0.8, list = FALSE, times = 1)
    train <- data[trainIndex, ]
    test <- data[-trainIndex, ]

    # Define the model
    model <- caret::train(scramble ~ ., data = train, method = "rf", trControl = trainControl(method = "cv", number = 5))
    
    # Make predictions on the test set
    predictions <- predict(model, newdata = test)

    # Store the result for this iteration
    importances[[x]] <- varImp(model$finalModel)
    result[[x]] <- F1_Score(predictions, test$scramble)
  }
  # Combine the results for this iteration into the stat list
  names(importances) <- paste(i, seq_along(importances), sep = "_")
  names(result) <- paste(i, seq_along(result), sep = "_")
  list(result, importances)
} -> result_list_null

# Stop the parallel backend
stopCluster(cl)
registerDoSEQ()
stat_null = list()
F1_null = result_list_null[[1]]
# Combine the results into the stat list
stat_null <- do.call("rbind", F1_null)

```

####try calculating ROC curves instead of F1 scores
```{r}
library(foreach)
library(doParallel)
library(caret)
library(randomForest)
library(pROC)
library(withr)
library(cowplot)
library(svglite)


# Set the number of cores to use
num_cores <- 6
cl <- makeCluster(num_cores)
registerDoParallel(cl)


# Create a list to store the results
stat <- list()
roc_curves <- list()
data = data <- cbind(all[[1]], group_index)
#prog <- rownames(data[data$group_index == "progressor",])
#nonprog <- sample(rownames(data[data$group_index == "nonprogressor",]), min(table(status)), replace = FALSE)
#save downsampled patients
#downsampled = cbind(prog, nonprog)
#colnames(downsampled) = c("prog", "nonprog")
#write.csv(downsampled, "./../../../../../data/Risom_breast/downsamples_patients.csv")

# Loop over the data
foreach(i = 1:length(all), .packages = c("caret", "randomForest", "tidyverse", "pROC", "withr")) %dopar% {
  # Combine index variable with data
  data <- cbind(all[[i]], group_index)

    # Initialize a list to store individual ROC curves

    #downsamle majority class for balanced dataset
    
    
    data <- data[rownames(data) %in% c(prog, nonprog), ]
    
    # Split data into training and test sets
    #trainIndex <- caret::createDataPartition(data$group_index, p = 0.8, list = FALSE, times = 1)
    #train <- data[trainIndex, ]
    #test <- data[-trainIndex, ]
    
    # Define the model
    
    model <- with_seed(1, caret::train(group_index ~ ., data = data, method = "glm", metric = "ROC", trControl = trainControl(method = "cv", number = 10,
                                                                                                 classProbs = TRUE,
                                                                                                summaryFunction = twoClassSummary,
                                                                                                savePredictions = TRUE)))
    
    roc(model$pred$obs, model$pred[, 3], quiet = TRUE)

    
} -> result_list



names(result_list) = names(all)
# Extract individual ROC curves and combine them
#all_roc_curves <- do.call(c, result_list[[3]])

# Plot the average ROC curve
#plot(do.call(c, all_roc_curves), col = "darkorange", main = "Average ROC Curve", lwd = 2, col.main = "navy")
#plot(roc_curve, col = "darkorange", main = "Average ROC Curve", lwd = 2, col.main = "navy", xlim = c(1, 0), ylim = c(0, 1))
# names(result_list) = sub("_sublineage.csv", "", names(all))
# names(result_list) = sub("_delaunay", "", names(result_list))

# for (i in 1:length(result_list)){
# plot(result_list[[i]], main = names(result_list)[i])
#}
 


###################
# Plot all ROC curves on the same graph
# Define colors for each curve
# Plot ROC curves using plot() function
#png("./../../results_Risom/ROC_plot_stable.png", width = 900, height = 700, res =150)  # Specify the file name and dimensions

svglite("./../../results_Risom/ROC_plot_wolegend.svg", width = 5, height = 4.5)  # Specify the file name and dimensions

plot(NULL, type = "n", xlim = c(1, 0), ylim = c(0, 1), xlab = "Specificity", ylab = "Sensitivity", main = "ROC Curves tools")

# Define colors for each curve
curve_colors <- c("black", "blue", "darkgreen", "orange", "purple", "pink", "red")

# Plot each ROC curve
for (i in seq_along(result_list)) {
  roc_curve <- result_list[[i]]
  lines(roc_curve, col = curve_colors[i], lwd = 2)
}

names(result_list) = sub(".csv", "", names(all))
names(result_list) = sub("_delaunay", "", names(result_list))


# Assuming legend_names is your vector of legend names
# Replace this with your actual vector
legend_names <- names(result_list)

# Add legend with custom names
#legend("bottomright", legend = legend_names, col = curve_colors, lwd = 1, cex = 0.7)

dev.off()

```

Get auc table from ROC curves
```{r}
library(gridSVG)
library(grid)
library(gridExtra)
library(gridSVG)
library(ggplot2)
library(ggtext)

auc = list()
for (i in 1:length(result_list)) {
  auc[[i]] = result_list[[i]]$auc
}
auc = unlist(auc)
auc = as.data.frame.matrix(t(cbind(legend_names, auc)))
colnames(auc) = auc[1,]
auc = auc[-1,]

write.csv(auc, "./../../results_Risom/auc.csv")

```


Can I do feature filtering before?

```{r}
####try calculating ROC curves instead of F1 scores

library(foreach)
library(doParallel)
library(caret)
library(randomForest)
library(pROC)
library(withr)
library(cowplot)

# Set the number of cores to use
num_cores <- 6
cl <- makeCluster(num_cores)
registerDoParallel(cl)
importances <- list()
# Set the number of iterations
num_iterations <- 10

# Create a list to store the results
stat <- list()
roc_curves <- list()
# Loop over the data
foreach(i = 1:length(all), .combine = c, .packages = c("caret", "randomForest", "tidyverse", "pROC")) %dopar% {
  # Combine index variable with data
  data <- cbind(all[[i]], group_index)
  
  # Create a list to store the results for this iteration
  result <- list()
    # Initialize a list to store individual ROC curves
  

    #downsamle majority class for balanced dataset
    prog <- rownames(data[data$group_index == "progressor",])
    nonprog <- sample(rownames(data[data$group_index == "nonprogressor",]), min(table(status)), replace = FALSE)
    
    data <- data[rownames(data) %in% c(prog, nonprog), ]
    
    # Split data into training and test sets
    #trainIndex <- caret::createDataPartition(data$group_index, p = 0.8, list = FALSE, times = 1)
    #train <- data[trainIndex, ]
    #test <- data[-trainIndex, ]
    
    # Define the model
    
    model <- caret::train(group_index ~ ., data = data, method = "glm", metric = "ROC", trControl = trainControl(method = "cv", number = 10,
                                                                                                 classProbs = TRUE, 
                                                                                                summaryFunction = twoClassSummary,
                                                                                                savePredictions = TRUE))
    
    roc_curve = roc(model$pred$obs, model$pred[, 3], direction = "auto",  quiet = TRUE)
    roc_curves[[x]] <- roc_curve
    # Make predictions on the test set
    #predictions <- predict(model, newdata = test, type = "prob")  # Obtain class probabilities
    names(roc_curves) = names(all)[i]
    # Calculate ROC curve
    #roc_curve <- roc(ifelse(test$group_index == "progressor", 1, 0), predictions[, 2], drop_intermediate = FALSE)  # Assuming "progressor" is the positive class
    
    
    # Store the result for this iteration
    #importances[[x]] <- varImp(model$finalModel)
    #result[[x]] <- auc(roc_curve)  # Store the AUC instead of F1 score
  
  
  # Combine the results for this iteration into the stat list
  #names(importances) <- paste(i, seq_along(importances), sep = "_")
  #names(roc_curves) <- paste(x, names(all)[i], sep = "_")
  roc_curves
  #list(result, importances, roc_curves)
} -> result_list


###################
# Plot all ROC curves on the same graph
# Define colors for each curve
# Plot ROC curves using plot() function
plot(NULL, type = "n", xlim = c(1, 0), ylim = c(0, 1), xlab = "Specificity", ylab = "Sensitivity", main = "ROC Curves tools")

# Define colors for each curve
curve_colors <- c("red", "blue", "darkgreen", "orange", "purple")

# Plot each ROC curve
for (i in seq_along(result_list)) {
  roc_curve <- result_list[[i]]
  lines(roc_curve, col = curve_colors[i], lwd = 2)
}

names(result_list) = sub("_sublineage.csv", "", names(all))
names(result_list) = sub("_delaunay", "", names(result_list))


# Assuming legend_names is your vector of legend names
# Replace this with your actual vector
legend_names <- names(result_list)

# Add legend with custom names
legend("bottomright", legend = legend_names, col = curve_colors, lwd = 1, cex = 0.7)
```


Name stats correctly

```{r}

df = as.data.frame.matrix(do.call("rbind", stat))
df$tool = rep(names(all), each = 100)
colnames(df) = c("F1", "FDR", "Run")

length(names(all))
# add F1 baseline
#base = as.data.frame.matrix(stat_null)
#base$tool = rep("F1_baseline", 100)
#colnames(base) = c("F1", "FDR", "Run")
# bind baseline and toolresults together
#df = rbind(df, base)

```


Create plot to show comparison
```{r}
# generate dataset

df$Run <- sub("_sublineage.csv", "", df$Run)
df$Run <- sub("_delaunay", "", df$Run)
df <- na.omit(df)

```

# color abundances

Create boxplot as Denis wanted it
```{r, fig.width=6, fig.height = 4}

unique(df$Run)
image = ggplot(df, aes(x = factor(Run), y = F1)) +
  geom_boxplot() +
  geom_jitter(color="black", size=0.5, alpha=0.9) +
  theme_test()  +
  theme(axis.text.x = element_text(size = 9, angle = 90, vjust = 0.5, hjust = 1)) +
  xlab("Tool") +
  ylab("F1 score (random forest)") +
  #scale_x_discrete(labels=c('0.12 - 0.18', '0.15 - 0.20', '0.17 - 0.22', '0.22 - 0.23', '0.25')) +
  scale_color_discrete(name = "Cohort comparison") +
  scale_colour_brewer(palette = "Dark2") +ylim(0.2,1)
#dev.off()
#ggsave(file = "./../../results_Risom/F1_scores_celllineage.svg", plot = image, width = 3, height = 5.5)

```


### Continue with feature importances

```{r, fig.width=8, fig.height = 7}
features = result_list[seq(2, length(result_list), by = 2)]
names(features) = unique(names(all))

for (i in 1:length(features)){
  features[[i]] <- do.call("cbind", features[[i]])
}

feat_mean = list()
for (i in 1:length(features)){
  feat_mean[[i]] <- rowMeans(features[[i]])
  
}
names(features) = sub("_sublineage.csv", "", names(features))
names(features) = sub("_delaunay", "", names(features))
names(feat_mean) = names(features)
feat_cos = do.call("rbind", feat_mean)
pheatmap(feat_cos)

library(Radviz)
# Calculate cosine similarity matrix
mat <- t(feat_cos)
sim.mat <- cosine(mat)
ncol(mat)
dim(sim.mat)




pheatmap(sim.mat)
ggsave(file = "./../../results_Risom/cosinesim_scores_sublineage.svg", plot = pheatmap(sim.mat), width = 5.5, height = 5)


```

Look at feature means
```{r}
feat_means = do.call("rbind", feat_mean)
pheatmap(feat_means)

ggsave(file = "./../../results_Risom/featureimp_sublineage.svg", plot = pheatmap(feat_means), width = 18, height = 4.5)

```


Generate ground truth to measure with cosine similarity
```{r}
# these are proximity values from simulation, those should make the rank

# generate vector to fill with values for symmetric dataset
#vec = sub("X", "", rownames(features[[1]]))
#ran = c(0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25)
#self0_0.6 = c(0.60, 0.13, 0.13, 0.14, 0.13, 0.29, 0.29, 0.29, 0.13, 0.29, 0.29, 0.29, 0.14, 0.29, 0.29, 0.28)
#self0_0.45 = c(0.45, 0.18, 0.18, 0.19, 0.18, 0.27, 0.28, 0.27, 0.18, 0.28, 0.27, 0.27, 0.19, 0.27, 0.27, 0.27)

# for asymmetric dataset
vec = sub("X", "", rownames(features[[1]]))
ran = c(0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25)
self0_0.6 = c(0.13, 0.6, 0.13, 0.14,0.29, 0.13, 0.29, 0.29, 0.29, 0.13, 0.29, 0.29, 0.29, 0.14, 0.29, 0.28)
self0_0.45 = c(0.18, 0.45, 0.18, 0.19, 0.28, 0.18, 0.27, 0.27, 0.27, 0.19, 0.27, 0.27, 0.27, 0.18, 0.28, 0.27)

# for sym dataset
#ranks = data.frame(ran_vs_self_0.6 = abs(ran - self0_0.6),
#                   ran_vs_self_0.45 = abs(ran - self0_0.45),
#                   self_0.45_vs_self_0.6 = abs(self0_0.6 - self0_0.45))
#asym
ranks = data.frame(cross01_0.6_vs_ran = abs(ran - self0_0.6),
                   cross01_0.45_vs_ran = abs(ran - self0_0.45),
                   cross01_0.45_vs_cross01_0.6 = abs(self0_0.6 - self0_0.45))#

rownames(ranks) = vec

```
Calcuate 100 cosine simuílarities for each tool for each comparison

```{r}
# only for dataframes with length 16: 
# function for cosine similarity +1 over 2
 cosine_similarity <- function(vector1, vector2) {
      dot_product <- sum(vector1 * vector2)
      magnitude1 <- sqrt(sum(vector1^2))
      magnitude2 <- sqrt(sum(vector2^2))
    return(((dot_product / (magnitude1 * magnitude2)+1)/2))
 }

cosine_similarities = list()

for (i in seq_along(features)) {
  if (nrow(features[[i]]) == 16) {
    if (grepl(colnames(ranks)[1], names(features)[i]) == T) {
      # Funktion zur Berechnung der Kosinus-Ähnlichkeit
      ground_truth <- as.vector(ranks[, 1])
      # Berechne die Kosinus-Ähnlichkeit für jede Spalte
      cosine_similarities[[i]] <- sapply(features[[i]], function(col) {
        cosine_similarity(col, ground_truth)
      })
    } else if (grepl(colnames(ranks)[2], names(features)[i]) == T) {
      # Funktion zur Berechnung der Kosinus-Ähnlichkeit
      ground_truth <- as.vector(ranks[, 2])
      # Berechne die Kosinus-Ähnlichkeit für jede Spalte
      cosine_similarities[[i]] <- sapply(features[[i]], function(col) {
        cosine_similarity(col, ground_truth)
      })
    } else if (grepl(colnames(ranks)[3], names(features)[i]) == T) {
      # Funktion zur Berechnung der Kosinus-Ähnlichkeit
      ground_truth <- as.vector(ranks[, 3])
      # Berechne die Kosinus-Ähnlichkeit für jede Spalte
      cosine_similarities[[i]] <- sapply(features[[i]], function(col) {
        cosine_similarity(col, ground_truth)
      })
    }
  } 
}


names(cosine_similarities) = names(features)
cosine_similarities <- Filter(function(x) !is.null(x), cosine_similarities)
cosine_similarities = as.data.frame(do.call("rbind", cosine_similarities ))
```

Visualization and wrangling for ir

```{r, fig.width=15, fig.height=5}
# wrangling
back = cosine_similarities
cosine_similarities = as.data.frame(back)

colnames(cosine_similarities) = 1:ncol(cosine_similarities)
cosine_similarities$comparison <- sub(".*_sim_", "", rownames(cosine_similarities))
#cosine_similarities$comparison <- sub("^.*0.[0-9]+_cross01", "cross01", cosine_similarities$comparison)
# this is the comaprison without abundance: 
cosine_similarities$comparison <- sub(".*_ab._[0-9]\\.[0-9]*_", "", rownames(cosine_similarities))#, just took me long and I did not want to delete it
cosine_similarities$tool <- sub("_ab.*", "", rownames(cosine_similarities))
cosine_similarities$abundance_ct_0 = sub("^.*ab0_", "", rownames(cosine_similarities))
#cosine_similarities$abundance_ct_0 = sub("sim.*$", "", cosine_similarities$abundance_ct_0)
#cosine_similarities$abundance_ct_0 = sub("_cross01_.*_vs_.*$", "", cosine_similarities$abundance_ct_0)
#cosine_similarities$abundance_ct_0 = sub("_[ran|self].*", "", cosine_similarities$abundance_ct_0)
cosine_similarities$abundance_ct_0 = sub("_cross.*", "", cosine_similarities$abundance_ct_0)

# now long data format
cosine_similarities = gather(cosine_similarities, value = "cosine_similarity", key = "run", - c(tool, comparison, abundance_ct_0))


#fine visualization with splitting comparison
#pdf("./../../results_4ct_sym_0.2grid_self/plots/sym_self00_cosine_similarity_counts_ct_normalized.pdf", width =17.5, height = 4.5)
#pdf("./../../results_4ct_sym_0.2grid_self/plots/sym_self00_cosine_similarity_scaled_counting_0.6.pdf", width = 5.5, height = 4.5)
#pdf("./../../results_4ct_asym_0.2grid_self/plots/Giotto_cosine_correct_order_asym.pdf", width = 4.2, height = 4.5)
image2 = ggplot(cosine_similarities, aes(x = factor(abundance_ct_0), y = cosine_similarity, color = comparison, group = interaction(comparison, abundance_ct_0))) +
  geom_boxplot() +
  facet_grid(. ~ tool) +
  theme_test() +
  theme(axis.text.x = element_text(size = 9, angle = 90, vjust = 0.5, hjust = 1)) +
  xlab("Abundance ct 0") +
  ylab("Cosine similarity") +
  scale_x_discrete(labels=c('0.12 - 0.18', '0.15 - 0.20', '0.17 - 0.22', '0.22 - 0.23', '0.25')) +
  scale_color_discrete(name = "Cohort comparison") +
  scale_colour_brewer(palette = "Dark2") + ylim(0.57,0.98)
#dev.off()
ggsave(file = "./../../results_4ct_asym/asym_cosinesim_SEAfixed.svg", plot = image2, width = 16, height = 5)

image2
```















