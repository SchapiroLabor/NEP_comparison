
---
title: "Comparison_SCNA"
author: "Chiara Schiller"
date: "2023-04-17"
output: html_document
---

## Compare all tools, results saved in folder 2 up

```{r}

# Install packages
library(FactoMineR)
library(ggcorrplot)
library(corrr)
library(readr)
library(ggfortify)
library(ggplot2)
library(randomForestSRC)
library(caret)
library(tidyverse)

```

Load in all different result files
```{r}
csv_dir = "./../../results_4ct_sym/"
data <- list.files(path = csv_dir, recursive = FALSE, pattern = "\\.csv$")
all = list()
for (i in 1:length(data)){
  all[[i]] <- as.data.frame(read_csv(paste0(csv_dir,data[i])))
  #rownames(all[[i]]) = sub("4ct_self", "", as.vector(all[[i]][,1]))
  rownames(all[[i]]) = as.vector(all[[i]][,1])
  rownames(all[[i]]) = sub(".csv", "", rownames(all[[i]]))
  all[[i]] = all[[i]][,-1]


# switch interactions colnames Misty
colnames(all[[i]]) = sub("(.*)_(.*)", "\\2_\\1", colnames(all[[i]]))}

#switch back for histoCAT
for(i in grep("histo", data)){
  colnames(all[[i]]) = sub("(.*)_(.*)", "\\2_\\1", colnames(all[[i]]))
  }

```
Make 16 features for GIOTTO -- gives later error, see how to solve it for Giotto

```{r}
giotto_inidces <- which(sapply(all, function(df) ncol(df) == 10))

for (i in giotto_inidces){
  dob = all[[i]][, !colnames(all[[i]]) %in% c("0_0", "1_1", "2_2", "3_3")]
  colnames(dob) = sub("(.*)_(.*)", "\\2_\\1", colnames(dob))
  all[[i]] = cbind(all[[i]] , dob)
}


##make all datasets the same order and without any numbers in the feature names
modify_row_names <- function(row_name) {
  numbers <- gsub("\\D", "", row_name)
  modified_name <- paste(strsplit(numbers, "")[[1]], collapse = "_")
  return(modified_name)
}

for (i in 1:length(all)){
    colnames(all[[i]]) <- as.vector(sapply(colnames(all[[i]]), modify_row_names))
    }


# correct order for ground truth later 
ordered_cols <- c("0_0", "0_1", "0_2", "0_3", "1_0", "1_1", "1_2", "1_3", "2_0", "2_1", "2_2", "2_3", "3_0", "3_1", "3_2", "3_3")
# Combine the results into the stat list
for (i in 1:length(all)) {
      # Reorder rows of dataset1 using the ordered row names
      all[[i]] <- all[[i]][, ordered_cols , drop = FALSE]
  }

#look at correct names
for (i in 1:length(all)){
print(colnames(all[[i]]))
  }

```





Create defining group columns within datasets
```{r}
df_list = list()

for (i in 1:length(all)){
  #all[[i]]$preference <- sub("_ab.*sim_\\d+$", "", rownames(all[[i]]))
  #all[[i]]$preference <- sub("self_", "self0_", all[[i]]$preference)
  all[[i]]$preference <- sub("_ab.*$", "", rownames(all[[i]]))
  all[[i]]$preference <- sub("_ab.*$", "", all[[i]]$preference)
  all[[i]]$abundance <- sub(".*ab", "ab", rownames(all[[i]]))
  all[[i]]$abundance = sub("_[0-9]+$", "", all[[i]]$abundance)
  all[[i]]$abundance = sub("_sim", "", all[[i]]$abundance)
}

#data[9]


```

Gereate datasets with only the two groups to compare, give it the right naming and then the rest of the script should stay the same :)
```{r}

```

 Naming convention: Tool_x_vs_y

```{r}
# prepare lists
df_comb = list()
split_string <- strsplit(data, "4ct")
#toollist <- sub("_+$", "", split_string[[1]][1])
#part_after_sim <- paste("sim", split_string[[1]][2], sep = "")

# now loop through every combination of abundances are preferences to compare all tools withtin their abundances
for (i in 1:length(all)){
  combs <- combn(unique(all[[i]]$preference), 2)
  pref_comb <- apply(combs, 2, function(x) c(as.character(x[1]), as.character(x[2])))
  for (a in unique(all[[i]]$abundance)){
  df = all[[i]] %>% filter(abundance == a)
    for (p in 1:ncol(pref_comb)){
      df2 = df %>% filter(preference %in% pref_comb[,p]) 
      df_comb[[paste(sub("_+$", "", split_string[[i]][1]), unique(df2$abundance), unique(df2$preference)[1], "vs", unique(df2$preference)[2], sep = "_")]] = df2 %>% select(-preference, -abundance)
      #df_comb[[paste(sub("_+$", "", split_string[[i]][1]), unique(df2$abundance), paste(pref_comb[,p], sep = "_vs_"), sep = "_")]] = df2
      }
    }
  }

# these are the comparisons we have:
names = names(df_comb)

names(df_comb)

library(tidyverse)
library(factoextra)
library(pheatmap)

all = df_comb

```


 

Create heatmap for all to see, what to expect
```{r}
library(tidyverse)
library(factoextra)
library(pheatmap)


for (i in 1:length(all)){
  pheatmap(all[[i]], treeheight_row = 0, treeheight_col = 0, main = names(all)[i], cluster_rows = F)
}

#pheatmap(rbind(colMeans(all[[13]][1:100,]), colMeans(all[[i]][101:200,])), treeheight_row = 0, treeheight_col = 0, main = names(all)[i], cluster_rows = F)

#generate heatmap for all
# Misty und SEA haben noch ein self06 datenfile intus.

# save one plot to show purpose
#
#png("./../../../../Figures/raw/Comparison/heatmap_SEA_0.24_0.6vsran.png", height = 400, width = 550, res = 150)
#colnames(all[[3]]) = sub("X", "", colnames(all[[3]]))
#pheatmap(all[[3]], treeheight_row = 0, treeheight_col = 0, show_rownames = FALSE)
#dev.off()


#names(all)[102]
```
Create PCA plot of all results
```{r}
for (i in 1:length(all)){
df = all[[i]]
# some datasets have zero variance column (sigval in histocat). They cannot be scaled
  if(0 %in% apply(df, 2, sd)){
    pca_res <- prcomp(df)
  }else{
    pca_res <- prcomp(df, scale. = TRUE)
  }
df$group = sub("_ab.*", "", rownames(df))

print(autoplot(pca_res, data = df, colour = 'group') +
      ggtitle(names(all)[i]) +
        theme_bw()
      )
}

# save one plot to show purpose


#df = all[[143]]
#pca_res <- prcomp(df, scale. = TRUE)
#df$group = sub("_ab.*", "", rownames(df))###

#png("./../../../../Figures/raw/Comparison/PCA_SEA_example.png", height = 400, width = 600, res = 150)
#autoplot(pca_res, data = df, colour = 'group') +
#      ggtitle(names(all)[143]) +
#        theme_bw()
#dev.off()

```
Create comparison of interactino score distributions
```{r}
# select column of interest (specific cell cell interaction)
COI = 1


for (i in 1:length(all)){
  groups = rep(unlist(strsplit(names(all[i]), "_vs_")), each = 100)
  data = as.data.frame(cbind(rownames(all[[i]]), as.numeric(all[[i]][,COI]), groups))
  data$V2 = as.numeric(data$V2)
  
  print(ggplot(data, aes(x = V2)) +
  geom_histogram() +
  facet_grid(. ~ groups) +
  labs(title = names(all)[i], x = "interaction_value", y = "Frequency") +
    theme_classic()
  )
  
}

```


Set functions for random forest and F1 statistics
```{r}
stat = list()
# Load required packages
library(caret)
library(randomForest)
# Create an index variable for the two groups
group_index <- rep(c("A","B"), each=100)

# write F1 and FDR function
# Calculate the F1 score
F1_Score <- function(predictions, actual) {
  TP <- sum(predictions == "B" & actual == "B")
  FP <- sum(predictions == "B" & actual == "A")
  FN <- sum(predictions == "A" & actual == "B")
  precision <- TP / (TP + FP)
  recall <- TP / (TP + FN)
  F1 <- 2 * precision * recall / (precision + recall)
  FDR <- FP / (TP + FP)
  return(c(F1, FDR))
}

# Set seed for reproducibility
set.seed(123)
```

Fix connection issue
```{r}
unregister_dopar <- function() {
  env <- foreach:::.foreachGlobals
  rm(list=ls(name=env), pos=env)
}
unregister_dopar()
```


Parallelize 100 iterations
```{r}
library(foreach)
library(doParallel)
library(caret)
library(randomForest)

# Set the number of cores to use
num_cores <- 6
cl <- makeCluster(num_cores)
registerDoParallel(cl)
importances = list()
# Set the number of iterations
num_iterations <- 100

# Create a list to store the results
stat <- list()

# Loop over the data
foreach(i = 1:length(all), .combine = c, .packages = c("caret","randomForest")) %dopar% {
  # Combine index variable with data
  data <- cbind(all[[i]], group_index)
  # Create a list to store the results for this iteration
  result <- list()
  
  for (x in 1:num_iterations){
    # Split data into training and test sets
    trainIndex <- caret::createDataPartition(data$group_index, p = 0.8, list = FALSE, times = 1)
    train <- data[trainIndex, ]
    test <- data[-trainIndex, ]

    # Define the model
    model <- caret::train(group_index ~ ., data = train, method = "rf", trControl = trainControl(method = "cv", number = 5))
    
    # Make predictions on the test set
    predictions <- predict(model, newdata = test)

    # Store the result for this iteration
    importances[[x]] <- varImp(model$finalModel)
    result[[x]] <- F1_Score(predictions, test$group_index)
  }
  # Combine the results for this iteration into the stat list
  names(importances) <- paste(i, seq_along(importances), sep = "_")
  names(result) <- paste(i, seq_along(result), sep = "_")
  list(result, importances)
} -> result_list

# Stop the parallel backend
stopCluster(cl)
registerDoSEQ()
stat = list()
F1 = result_list[seq(1, length(result_list), by = 2)]
# Combine the results into the stat list
for (i in seq_along(F1)) {
  
  stat[[i]] <- do.call("rbind", F1[[i]])
}

saveRDS(result_list, "./../../results_4ct_sym/rf_result_lists/sym_complete.rds")
#see = readRDS("./../../results_4ct_cross01/count_histoCATSEA_result_list_4ct_cross01.rds")

#result_list = readRDS("./../../results_4ct_asym_0.2grid_self/Misty_cross/Misty_F1_correct_order.rds")
# loading results wo spatialLDA
#all = all[c(1:length(all)) %notin% grep("SpatialLDA", names(all))]
```

Make an F1 baseline with scrambled labels to show interpretability of results

```{r}
library(foreach)
library(doParallel)
library(caret)
library(randomForest)

# Set the number of cores to use
num_cores <- 6
cl <- makeCluster(num_cores)
registerDoParallel(cl)
importances = list()
# Set the number of iterations
num_iterations <- 100
scramble <- rep(rep(c("A","B"), each=1), 100)
# Create a list to store the results
stat <- list()

# Loop over the data
foreach(i = 1, .combine = c, .packages = c("caret","randomForest")) %dopar% {
  # Combine index variable with data
  data <- cbind(all[[i]], scramble)
  # Create a list to store the results for this iteration
  result <- list()
  
  for (x in 1:num_iterations){
    # Split data into training and test sets
    trainIndex <- caret::createDataPartition(data$scramble, p = 0.8, list = FALSE, times = 1)
    train <- data[trainIndex, ]
    test <- data[-trainIndex, ]

    # Define the model
    model <- caret::train(scramble ~ ., data = train, method = "rf", trControl = trainControl(method = "cv", number = 5))
    
    # Make predictions on the test set
    predictions <- predict(model, newdata = test)

    # Store the result for this iteration
    importances[[x]] <- varImp(model$finalModel)
    result[[x]] <- F1_Score(predictions, test$scramble)
  }
  # Combine the results for this iteration into the stat list
  names(importances) <- paste(i, seq_along(importances), sep = "_")
  names(result) <- paste(i, seq_along(result), sep = "_")
  list(result, importances)
} -> result_list_null

# Stop the parallel backend
stopCluster(cl)
registerDoSEQ()
stat_null = list()
F1_null = result_list_null[[1]]
# Combine the results into the stat list
stat_null <- do.call("rbind", F1_null)

```


Name stats correctly

```{r}

df = as.data.frame.matrix(do.call("rbind", stat))
df$tool = rep(names(all), each = 100)
colnames(df) = c("F1", "FDR", "Run")

length(names(all))
# add F1 baseline
base = as.data.frame.matrix(stat_null)
base$tool = rep("F1_baseline", 100)
colnames(base) = c("F1", "FDR", "Run")
# bind baseline and toolresults together
df = rbind(df, base)

```


Create plot to show comparison
```{r}
# generate dataset

split_strings <- sapply(df$Run, function(x) {
  split_string <- strsplit(x, "[Ss]im")
  part_before_sim <- sub("_+$", "", split_string[[1]][1])
  part_after_sim <- paste("sim", split_string[[1]][2], sep = "")
  return(list(part_before_sim, part_after_sim))
})
# Get the parts before and after "sim"
df$comparison <- sub(".*_ab", "ab", df$Run)
# this is the comaprison without abundance: df$comparison <- sub(".*_ab._[0-9]\\.[0-9]*_", "", names(all)), just took me long and I did not want to delete it
df$tool <- sub("_ab.*", "", df$Run)

```

# color abundances

```{r, fig.height=12, fig.width=12}
df$abundance = sub("^(.+?)_[^_]+_(.*)", "\\1", df$comparison)
  
```

Create boxplot as Denis wanted it
```{r, fig.width=20, fig.height = 5}
# exclude sigval value in histocat

df$abundance = sub("^(.+?)_[^_]+_(.*)", "\\1", df$comparison)
# separate the comparison column into two columns using separate() function
df$comparison_preference = sub("^[^_]*_[^_]*_", "", df$comparison)
#df_sort <- df[order(df$abundance, df$tool),]
#df_sort$abundance_ct_0 = sub("^ab0_", "", df_sort$abundance)
df$abundance_ct_0 = sub("^ab0_", "", df$abundance)
df$comparison_preference = as.factor(df$comparison_preference)

df$tool = sub("SEA_bi_100iter_direction_delaunay", "SEA_bi_direction_delaunay", df$tool)
df$tool = sub("IMCR_histoCAT_delaunay_p_lt", "IMCR_histoCAT_delaunay", df$tool)

df$comparison = sub("ran_vs_self", "", "")
df$tool = sub("10motifs", "k9_10motifs", df$tool)

# shortly subset:
#df = df %>% filter(tool != "Giotto_delaunay")
#pdf("./../../results_4ct_sym_0.2grid_self/plots/sym_self00_comparison_abundance_boxplots_with_SpatialLDA.pdf", width = 24, height = 4.5)
#pdf("./../../results_4ct_asym_0.2grid_self/plots/Giotto_F1_correct_order_asym.pdf", width = 4.5, height = 4.5)
image = ggplot(df, aes(x = factor(abundance_ct_0), y = F1, color = comparison_preference, group = interaction(comparison_preference, abundance_ct_0))) +
  geom_boxplot() +
  facet_grid(. ~ tool) +
  theme_test()  +
  theme(axis.text.x = element_text(size = 9, angle = 90, vjust = 0.5, hjust = 1)) +
  xlab("Abundance ct 0") +
  ylab("F1 score (random forest)") +
  scale_x_discrete(labels=c('0.12 - 0.18', '0.15 - 0.20', '0.17 - 0.22', '0.22 - 0.23', '0.25')) +
  scale_color_discrete(name = "Cohort comparison") +
  scale_colour_brewer(palette = "Dark2") +ylim(0.2,1)
#dev.off()
ggsave(file = "./../../results_4ct_sym/sym_F1.svg", plot = image, width = 13, height = 5)

```


### Continue with feature importances

```{r}
features = result_list[seq(2, length(result_list), by = 2)]
names(features) = unique(names(all))

for (i in 1:length(features)){
  features[[i]] <- do.call("cbind", features[[i]])
}


```




Generate ground truth to measure with cosine similarity
```{r}
# these are proximity values from simulation, those should make the rank

# generate vector to fill with values for symmetric dataset
vec = sub("X", "", rownames(features[[1]]))
ran = c(0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25)
self0_0.6 = c(0.60, 0.13, 0.13, 0.14, 0.13, 0.29, 0.29, 0.29, 0.13, 0.29, 0.29, 0.29, 0.14, 0.29, 0.29, 0.28)
self0_0.45 = c(0.45, 0.18, 0.18, 0.19, 0.18, 0.27, 0.28, 0.27, 0.18, 0.28, 0.27, 0.27, 0.19, 0.27, 0.27, 0.27)

# for asymmetric dataset
#vec = sub("X", "", rownames(features[[1]]))
#ran = c(0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25)
#self0_0.6 = c(0.13, 0.6, 0.13, 0.14,0.29, 0.13, 0.29, 0.29, 0.29, 0.13, 0.29, 0.29, 0.29, 0.14, 0.29, 0.28)
#self0_0.45 = c(0.18, 0.45, 0.18, 0.19, 0.28, 0.18, 0.27, 0.27, 0.27, 0.19, 0.27, 0.27, 0.27, 0.18, 0.28, 0.27)

# for sym dataset
ranks = data.frame(ran_vs_self_0.6 = abs(ran - self0_0.6),
                   ran_vs_self_0.45 = abs(ran - self0_0.45),
                   self_0.45_vs_self_0.6 = abs(self0_0.6 - self0_0.45))
#asym
#ranks = data.frame(cross01_0.6_vs_ran = abs(ran - self0_0.6),
##                   cross01_0.45_vs_ran = abs(ran - self0_0.45),
#                   cross01_0.45_vs_cross01_0.6 = abs(self0_0.6 - self0_0.45))#

rownames(ranks) = vec

```
Calcuate 100 cosine simuílarities for each tool for each comparison

```{r}
# only for dataframes with length 16: 
# function for cosine similarity +1 over 2
 cosine_similarity <- function(vector1, vector2) {
      dot_product <- sum(vector1 * vector2)
      magnitude1 <- sqrt(sum(vector1^2))
      magnitude2 <- sqrt(sum(vector2^2))
    return(((dot_product / (magnitude1 * magnitude2)+1)/2))
 }

cosine_similarities = list()

for (i in seq_along(features)) {
  if (nrow(features[[i]]) == 16) {
    if (grepl(colnames(ranks)[1], names(features)[i]) == T) {
      # Funktion zur Berechnung der Kosinus-Ähnlichkeit
      ground_truth <- as.vector(ranks[, 1])
      # Berechne die Kosinus-Ähnlichkeit für jede Spalte
      cosine_similarities[[i]] <- sapply(features[[i]], function(col) {
        cosine_similarity(col, ground_truth)
      })
    } else if (grepl(colnames(ranks)[2], names(features)[i]) == T) {
      # Funktion zur Berechnung der Kosinus-Ähnlichkeit
      ground_truth <- as.vector(ranks[, 2])
      # Berechne die Kosinus-Ähnlichkeit für jede Spalte
      cosine_similarities[[i]] <- sapply(features[[i]], function(col) {
        cosine_similarity(col, ground_truth)
      })
    } else if (grepl(colnames(ranks)[3], names(features)[i]) == T) {
      # Funktion zur Berechnung der Kosinus-Ähnlichkeit
      ground_truth <- as.vector(ranks[, 3])
      # Berechne die Kosinus-Ähnlichkeit für jede Spalte
      cosine_similarities[[i]] <- sapply(features[[i]], function(col) {
        cosine_similarity(col, ground_truth)
      })
    }
  } 
}


names(cosine_similarities) = names(features)
cosine_similarities <- Filter(function(x) !is.null(x), cosine_similarities)
cosine_similarities = as.data.frame(do.call("rbind", cosine_similarities ))
```

Visualization and wrangling for ir

```{r, fig.width=15, fig.height=5}
# wrangling
back = cosine_similarities
cosine_similarities = as.data.frame(back)

colnames(cosine_similarities) = 1:ncol(cosine_similarities)
cosine_similarities$comparison <- sub(".*_sim_", "", rownames(cosine_similarities))
#cosine_similarities$comparison <- sub("^.*0.[0-9]+_cross01", "cross01", cosine_similarities$comparison)
# this is the comaprison without abundance: 
cosine_similarities$comparison <- sub(".*_ab._[0-9]\\.[0-9]*_", "", rownames(cosine_similarities))#, just took me long and I did not want to delete it
cosine_similarities$tool <- sub("_ab.*", "", rownames(cosine_similarities))
cosine_similarities$abundance_ct_0 = sub("^.*ab0_", "", rownames(cosine_similarities))
#cosine_similarities$abundance_ct_0 = sub("sim.*$", "", cosine_similarities$abundance_ct_0)
#cosine_similarities$abundance_ct_0 = sub("_cross01_.*_vs_.*$", "", cosine_similarities$abundance_ct_0)
#cosine_similarities$abundance_ct_0 = sub("_[ran|self].*", "", cosine_similarities$abundance_ct_0)
cosine_similarities$abundance_ct_0 = sub("_cross.*", "", cosine_similarities$abundance_ct_0)

# now long data format
cosine_similarities = gather(cosine_similarities, value = "cosine_similarity", key = "run", - c(tool, comparison, abundance_ct_0))


#fine visualization with splitting comparison
#pdf("./../../results_4ct_sym_0.2grid_self/plots/sym_self00_cosine_similarity_counts_ct_normalized.pdf", width =17.5, height = 4.5)
#pdf("./../../results_4ct_sym_0.2grid_self/plots/sym_self00_cosine_similarity_scaled_counting_0.6.pdf", width = 5.5, height = 4.5)
#pdf("./../../results_4ct_asym_0.2grid_self/plots/Giotto_cosine_correct_order_asym.pdf", width = 4.2, height = 4.5)
image2 = ggplot(cosine_similarities, aes(x = factor(abundance_ct_0), y = cosine_similarity, color = comparison, group = interaction(comparison, abundance_ct_0))) +
  geom_boxplot() +
  facet_grid(. ~ tool) +
  theme_test() +
  theme(axis.text.x = element_text(size = 9, angle = 90, vjust = 0.5, hjust = 1)) +
  xlab("Abundance ct 0") +
  ylab("Cosine similarity") +
  scale_x_discrete(labels=c('0.12 - 0.18', '0.15 - 0.20', '0.17 - 0.22', '0.22 - 0.23', '0.25')) +
  scale_color_discrete(name = "Cohort comparison") +
  scale_colour_brewer(palette = "Dark2") + ylim(0.57,0.98)
#dev.off()
ggsave(file = "./../../results_4ct_sym/sym_cosinesim.svg", plot = image2, width = 13, height = 5)

  
```
########################################
From here on, it is just exploring more options for plotting interaction scores etc.






```{r}
# heatmap to see feature importances?

try = features[[grep("SpatialLDA_knn9_10motifs_ab0_0.25_ran_vs_self_0.6", names(features))]]
#rownames(try) = sub("(.*)_(.*)", "\\2_\\1", rownames(try))
try1 = as.data.frame.matrix(t(try)) %>% colMeans()
try2 = as.data.frame.matrix(t(try)) %>% colMeans()
try3 = as.data.frame.matrix(t(try)) %>% colMeans()
try4 = as.data.frame.matrix(t(try)) %>% colMeans()
try5 = as.data.frame.matrix(t(try)) %>% colMeans()
try6 = as.data.frame.matrix(t(try)) %>% colMeans()
try7 = as.data.frame.matrix(t(try)) %>% colMeans()
try8 = as.data.frame.matrix(t(try)) %>% colMeans()
try9 = as.data.frame.matrix(t(try)) %>% colMeans()
try10 = as.data.frame.matrix(t(try)) %>% colMeans()
try11 = as.data.frame.matrix(t(try)) %>% colMeans()
try12 = as.data.frame.matrix(t(try)) %>% colMeans()
try13 = as.data.frame.matrix(t(try)) %>% colMeans()
try14 = as.data.frame.matrix(t(try)) %>% colMeans()
try15 = as.data.frame.matrix(t(try)) %>% colMeans()

try = t(scale(t(rbind(try1, try2, try3, try4, try5, try6, try7, try8, try9, try10, try11, try12, try13, try14, try15, ranks$self_0.45_vs_self_0.6))))
try = t(scale(t(rbind(try1, try2, try3, try4, try5, ranks$cross01_0.6_vs_ran))))
try = t(scale(t(rbind(try1, try2, try3, try4, try5))))
try = t(scale(t(rbind(try1, try2, try3, try4, try5, ranks$ran_vs_self_0.45, try6, try7, try8, try9, try10, ranks$self_0.45_vs_self_0.6))))
rownames(try) = c('Misty_ran_vs_0.45_ab0.05', 'Misty_ran_vs_0.45_ab_0.1', 'Misty_ran_vs_0.45_ab_0.15', 'Misty_ran_vs_0.45_ab_0.2', 'Misty_ran_vs_0.45_ab_0.25', "ground_truth_ran_vs_0.45", 
                  'Misty_0.45_vs_0.6_ab0.05', 'Misty_0.45_vs_0.6_ab_0.1', 'Misty_0.45_vs_0.6_ab_0.15', 'Misty_0.45_vs_0.6_ab_0.2', 'Misty_0.45_vs_0.6_ab_0.25',  "ground_truth_0.45_vs_0.6")


rownames(try) = c('0.12 - 0.18', '0.15 - 0.20', '0.17 - 0.22', '0.22 - 0.23', '0.25', "ground_truth_0.6_vs_ran")
rownames(try) = c('0.12 - 0.18', '0.15 - 0.20', '0.17 - 0.22', '0.22 - 0.23', '0.25')

rownames(try) = c('IMCRclassic_0.05', 'IMCRclassic_0.1', 'IMCRclassic_0.15', 'IMCRclassic_0.2', 'IMCRclassic_0.25', 
                  'histoCAT_0.05','histoCAT_0.1', 'histoCAT_0.15','histoCAT_0.2', 'histoCAT_0.25', 
                  'SEAbi_0.05', 'SEAbi_0.1', 'SEAbi_0.15', 'SEAbi_0.2', 'SEAbi_0.25', "ground_truth")

pheatmap(try, treeheight_row = 0, treeheight_col = 0, cluster_rows = F)

# scaled to 1
#png("./../../../../Figures/raw/Comparison/heatmap_count50_increase_ABUNDANCES_OVERVIEW.png", height = 400, width = 550, res = 150)
png("./../../../../Figures/raw/images/heatmap_spatialLDA_featureimp_sym_ranvs06.png", height = 300, width = 750, res = 150)
colnames(try) = sub("`", "", colnames(try))
colnames(try) = sub("`", "", colnames(try))
#pheatmap(t(scale(try)), treeheight_row = 0, treeheight_col = 0, show_rownames = FALSE, cluster_rows = F)
pheatmap(try, treeheight_row = 0, treeheight_col = 0, cluster_rows = F)
dev.off()


pheatmap(t(ranks))
```

Just visualize it first, maybe the means

```{r}

# Calculate row means for each dataframe in the list
row_means <- lapply(features, function(df) rowMeans(df, na.rm = TRUE))
names(row_means) = unique(names)


# Group vectors by length
grouped_list <- split(row_means, lengths(row_means))

# Rbind vectors with the same length
combined_vectors <- lapply(grouped_list, function(x) do.call(rbind, x))

# Print the combined vectors
for (i in seq_along(combined_vectors)) {
  cat("Combined vectors with length", names(combined_vectors)[i], ":\n")
  print(combined_vectors[[i]])
}



ranks_16 = do.call("rbind", grouped_list[[2]])
1
```


calculate cosine similarity for ranks with binary count
```{r}
library(proxy)
try = ranks_16[grep(colnames(ranks[1]), rownames(ranks_16), value = TRUE), ]


### manual

given_vector = as.vector(ranks$cross01_06_vs_ran)
# Calculate cosine similarity between rows and the given vector
row_cosine_sim <- apply(try, 1, function(row) {
  dot_product <- sum(row * given_vector)
  magnitude_row <- sqrt(sum(row^2))
  magnitude_given <- sqrt(sum(given_vector^2))
  dot_product / (magnitude_row * magnitude_given)
})
```

Try to visualize
```{r}
class(row_cosine_sim)

res_cos = as.data.frame.matrix(cbind(as.numeric(row_cosine_sim), sub("_ab0.*$", "", names(row_cosine_sim))))
rownames(res_cos) = names(row_cosine_sim)
colnames(res_cos) = c("cosine_similarity", "method")
res_cos$cosine_similarity = as.numeric(res_cos$cosine_similarity)

ggplot(res_cos, aes(method, cosine_similarity)) +
  geom_boxplot() +
  theme_test() +
  theme(axis.text.x = element_text(size = 9, angle = 90, vjust = 0.5, hjust = 1)) 
```
#####

Now with the ones that have length 10

```{r}
# these are proximity values from simulation, those should make the rank

# generate vector to fill with values for symmetric dataset
#vec = sub("X", "", rownames(features[[80]]))
#ran = c(0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25)
#self0_0.6 = c(0.60, 0.13, 0.13, 0.14, 0.13, 0.29, 0.29, 0.29, 0.13, 0.29, 0.29, 0.29, 0.14, 0.29, 0.29, 0.28)
#self0_0.45 = c(0.45, 0.18, 0.18, 0.19, 0.18, 0.295, 0.295, 0.21, 0.18, 0.295, 0.295, 0.21, 0.19, 0.21, 0.21, 0.37)

# for asymmetric dataset
vec = sub("X", "", rownames(features[[80]]))
ran = c(0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5)
self0_0.6 = c(0.13, 0.6, 0.13, 0.14,0.29, 0.13, 0.29, 0.29, 0.29, 0.13, 0.29, 0.299, 0.29, 0.14, 0.29, 0.28)
self0_0.45 = c(0.18, 0.45, 0.18, 0.19, 0.28, 0.18, 0.27, 0.27, 0.27, 0.19, 0.27, 0.27, 0.27, 0.18, 0.28, 0.27)

# for sym dataset
#ranks = data.frame(ran_vs_self0_0.6 = abs(ran - self0_0.6),
#                   ran_vs_self0_0.45 = abs(ran - self0_0.45),
#                   self0_0.45_vs_self0_0.6 = abs(self0_0.6 - self0_0.45))

ranks = data.frame(cross01_06_vs_ran = abs(ran - self0_0.6),
                   cross01_045_vs_ran = abs(ran - self0_0.45),
                   cross01_045_vs_cross01_06 = abs(self0_0.6 - self0_0.45))

rownames(ranks) = vec
ranks
```


Just visualize it first, maybe the means

```{r}

ranks_10 = do.call("rbind", grouped_list[[1]])

```

calculate cosine similarity for ranks with binary count
```{r}
library(proxy)
try = ranks_10[grep(colnames(ranks[1]), rownames(ranks_16), value = TRUE), ]


### manual

given_vector = as.vector(ranks$cross01_06_vs_ran)
# Calculate cosine similarity between rows and the given vector
row_cosine_sim <- apply(try, 1, function(row) {
  dot_product <- sum(row * given_vector)
  magnitude_row <- sqrt(sum(row^2))
  magnitude_given <- sqrt(sum(given_vector^2))
  dot_product / (magnitude_row * magnitude_given)
})
```

Try to visualize
```{r}
class(row_cosine_sim)

res_cos = as.data.frame.matrix(cbind(as.numeric(row_cosine_sim), sub("_ab0.*$", "", names(row_cosine_sim))))
rownames(res_cos) = names(row_cosine_sim)
colnames(res_cos) = c("cosine_similarity", "method")
res_cos$cosine_similarity = as.numeric(res_cos$cosine_similarity)

ggplot(res_cos, aes(method, cosine_similarity)) +
  geom_boxplot() +
  theme_test() +
  theme(axis.text.x = element_text(size = 9, angle = 90, vjust = 0.5, hjust = 1)) 
```



















